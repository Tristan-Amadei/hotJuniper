{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfe83f2-41cb-49eb-b2b8-5c788db6d612",
   "metadata": {
    "id": "4bfe83f2-41cb-49eb-b2b8-5c788db6d612"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7c7cd5-1d8f-4f20-9e28-46e7fa2cb556",
   "metadata": {
    "id": "5d7c7cd5-1d8f-4f20-9e28-46e7fa2cb556"
   },
   "outputs": [],
   "source": [
    "from gilbert2d import gilbert2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "YAJuvbQdk4K7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAJuvbQdk4K7",
    "outputId": "20bd4c6c-626d-4d87-9adb-5ef088500ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Model running on {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320f5ba-7ba8-4e94-90b9-43716de90782",
   "metadata": {
    "id": "9320f5ba-7ba8-4e94-90b9-43716de90782"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129ee3b0-7c39-4dfe-8bf3-5b8ff2219c7b",
   "metadata": {
    "id": "129ee3b0-7c39-4dfe-8bf3-5b8ff2219c7b"
   },
   "outputs": [],
   "source": [
    "CLASSES = [\"asymetric\", \"banded\", \"locked\", \"butterfly\", \"no_pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbe6ad6-800f-4bf2-9b5c-2abc3b59cdc0",
   "metadata": {
    "id": "cdbe6ad6-800f-4bf2-9b5c-2abc3b59cdc0"
   },
   "outputs": [],
   "source": [
    "# Mapping int to categories\n",
    "int_to_cat = {\n",
    "    0: \"asymetric\",\n",
    "    1: \"banded\",\n",
    "    2: \"locked\",\n",
    "    3: \"butterfly\",\n",
    "    4: \"no_pattern\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a849af-6b7c-4ffd-83f2-3bf6c2971442",
   "metadata": {
    "id": "13a849af-6b7c-4ffd-83f2-3bf6c2971442"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"./data/X_train.npy\")\n",
    "y_train_df = pd.read_csv(\"./data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc087a3f-2484-4078-b708-d9779bc51176",
   "metadata": {
    "id": "dc087a3f-2484-4078-b708-d9779bc51176"
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_test_df = pd.read_csv(\"./data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdff4c-bd71-45c2-81b9-b3a160cef502",
   "metadata": {
    "id": "84cdff4c-bd71-45c2-81b9-b3a160cef502"
   },
   "source": [
    "## Flatten with Peano curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ceba34-f023-44d6-813c-56e84a971f38",
   "metadata": {
    "id": "f0ceba34-f023-44d6-813c-56e84a971f38"
   },
   "outputs": [],
   "source": [
    "def flatten_with_peano(image):\n",
    "    # Initialize empty flattened image array\n",
    "    flattened_image = np.zeros(np.prod(image.shape))\n",
    "    peano_points = gilbert2d(image.shape[0], image.shape[1])\n",
    "\n",
    "    flattened_image_index = 0\n",
    "    for row, col in peano_points:\n",
    "        flattened_image[flattened_image_index] = image[row, col]\n",
    "        flattened_image_index += 1\n",
    "\n",
    "    return flattened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35959286-b811-49d9-aeea-56de76fc1140",
   "metadata": {
    "id": "35959286-b811-49d9-aeea-56de76fc1140"
   },
   "outputs": [],
   "source": [
    "flattened_img_train = [flatten_with_peano(img) for img in X_train]\n",
    "flattened_img_test = [flatten_with_peano(img) for img in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5kVt7F2ce73u",
   "metadata": {
    "id": "5kVt7F2ce73u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(k_neighbors=10, n_jobs=-1)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(flattened_img_train, y_train_df['cat_num'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8466d6-cc01-46ad-b116-e09196751ce8",
   "metadata": {
    "id": "bd8466d6-cc01-46ad-b116-e09196751ce8"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(np.array(flattened_img_test), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df['cat_num'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4WrExqTkykt",
   "metadata": {
    "id": "b4WrExqTkykt"
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 14.54 GiB of which 41.44 MiB is free. Process 1991428 has 1.63 GiB memory in use. Process 3167848 has 11.08 GiB memory in use. Process 1211536 has 1.71 GiB memory in use. Process 2725564 has 52.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y_train\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mto(device), y_test\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacty of 14.54 GiB of which 41.44 MiB is free. Process 1991428 has 1.63 GiB memory in use. Process 3167848 has 11.08 GiB memory in use. Process 1211536 has 1.71 GiB memory in use. Process 2725564 has 52.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3293a-ed04-4416-8431-8c62aaa6098b",
   "metadata": {
    "id": "afa3293a-ed04-4416-8431-8c62aaa6098b"
   },
   "outputs": [],
   "source": [
    "print(f\"X_train shape -> {X_train.shape}, y_train shape -> {y_train.shape}\")\n",
    "print(f\"X_test shape -> {X_test.shape}, y_test shape -> {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52222955-42b5-495e-9063-363c3fd36908",
   "metadata": {
    "id": "52222955-42b5-495e-9063-363c3fd36908"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ueCxIS-_E0Dd",
   "metadata": {
    "id": "ueCxIS-_E0Dd"
   },
   "source": [
    "## Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05003b-e72a-4805-9bfd-9ea20cb013c1",
   "metadata": {
    "id": "5d05003b-e72a-4805-9bfd-9ea20cb013c1"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac694a-c74d-4956-8cce-500d99d24d5b",
   "metadata": {
    "id": "38ac694a-c74d-4956-8cce-500d99d24d5b"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageLSTM(nn.Module):\n",
    "    def __init__(self, input_size, lstm_outsize, num_layers, hidden_n, num_classes, bidirectional=True):\n",
    "        super(ImageLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, lstm_outsize, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc1 = nn.Linear(lstm_outsize * num_layers, hidden_n)\n",
    "        self.fc_out = nn.Linear(hidden_n, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = F.relu(self.fc1(lstm_out))\n",
    "        out = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FPLDoGqbzTFl",
   "metadata": {
    "id": "FPLDoGqbzTFl"
   },
   "outputs": [],
   "source": [
    "class ImageLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, lstm1, lstm2, num_layers, hidden_n, num_classes, bidirectional=True, dropout_rate=0.5):\n",
    "        super(ImageLSTMWithAttention, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, lstm1, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(num_layers * lstm1, lstm2, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.dropout_lstm = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(lstm2 * num_layers, hidden_n)\n",
    "        self.dropout_fc1 = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_n, num_classes)\n",
    "        self.attention_fc = nn.Linear(lstm2 * num_layers, 1)\n",
    "\n",
    "    def attention(self, lstm_out):\n",
    "        # Apply attention mechanism\n",
    "        energy = self.attention_fc(lstm_out)\n",
    "        # Squeeze only if the last dimension is 1\n",
    "        if energy.dim() == 2 and energy.size(1) == 1:\n",
    "            energy = energy.squeeze(-1)\n",
    "        weights = F.softmax(energy, dim=1).unsqueeze(-1)\n",
    "        attention_output = torch.sum(weights * lstm_out, dim=1)\n",
    "        return attention_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
    "\n",
    "        # Apply attention to the output of the second LSTM layer\n",
    "        #attention_output = self.attention(lstm_out2)\n",
    "\n",
    "        # Concatenate the attention output with the output of the second LSTM layer\n",
    "        #combined_output = torch.cat([lstm_out2[:, -1, :], attention_output], dim=1)\n",
    "\n",
    "        combined_output = self.dropout_lstm(lstm_out2)\n",
    "        fc1_out = F.relu(self.fc1(combined_output))\n",
    "        fc1_out = self.dropout_fc1(fc1_out)\n",
    "        out = self.fc_out(fc1_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hb9UUYAFOn0a",
   "metadata": {
    "id": "Hb9UUYAFOn0a"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming x is a 1D tensor with shape (sequence_length * batch_size * hidden_size)\n",
    "\n",
    "        # Reshape to (sequence_length, batch_size, hidden_size)\n",
    "        cur_batch_size = x.shape[0]\n",
    "        x = x.view(-1, cur_batch_size, self.hidden_size)\n",
    "\n",
    "        # Apply self-attention\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "        # Reshape back to (sequence_length * batch_size * hidden_size)\n",
    "        attn_output = attn_output.view(-1, self.hidden_size)\n",
    "        return attn_output\n",
    "\n",
    "class ImageLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size, lstm1, lstm2, num_layers, hidden_n, num_classes, num_attention_heads,\n",
    "                 bidirectional=True, dropout_rate=0.5, add_attention=True):\n",
    "        super(ImageLSTMWithAttention, self).__init__()\n",
    "        self.add_attention = add_attention\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size, lstm1, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.lstm2 = nn.LSTM(num_layers * lstm1, lstm2, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.self_attention = SelfAttention(lstm2 * num_layers, num_attention_heads)\n",
    "        self.dropout_lstm = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(lstm2 * num_layers * (2 if self.add_attention else 1), hidden_n)\n",
    "        self.dropout_fc1 = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_n, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out1, _ = self.lstm1(x)\n",
    "        lstm_out1 = self.dropout_lstm(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
    "\n",
    "        if self.add_attention:\n",
    "            attention_output = self.self_attention(lstm_out2)\n",
    "            lstm_out2 = torch.cat([lstm_out2, attention_output], dim=-1)\n",
    "            lstm_out2 = self.dropout_lstm(lstm_out2)\n",
    "\n",
    "        fc1_out = F.relu(self.fc1(lstm_out2))\n",
    "        fc1_out = self.dropout_fc1(fc1_out)\n",
    "        out = self.fc_out(fc1_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TPEDKYfGhZdP",
   "metadata": {
    "id": "TPEDKYfGhZdP"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        #images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and labels for balanced accuracy calculation\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_train_loss /= len(train_loader)\n",
    "\n",
    "    # Calculate balanced accuracy on the training set\n",
    "    train_balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
    "    train_acc = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "    return epoch_train_loss, train_acc, train_balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cGMwMFSTirqm",
   "metadata": {
    "id": "cGMwMFSTirqm"
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_val_loss /= len(val_loader)\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
    "    acc = accuracy_score(all_labels, all_predictions)\n",
    "    return epoch_val_loss, acc, balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FNGsTqj4hZWv",
   "metadata": {
    "id": "FNGsTqj4hZWv"
   },
   "outputs": [],
   "source": [
    "def train_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, num_epochs, plot_every=None, patience=np.inf):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_balanced_accuracies = []\n",
    "    val_balanced_accuracies = []\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    def print_metrics(epoch):\n",
    "      print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "            f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "            f\"Validation Loss: {epoch_val_loss:.4f}, \"\n",
    "            f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "            f\"Valid Accuracy: {val_accuracy:.4f}, \"\n",
    "            f\"Train Balanced Accuracy: {train_balanced_acc:.4f}, \"\n",
    "            f\"Validation Balanced Accuracy: {val_balanced_acc:.4f}, \"\n",
    "            f\"Time per epoch: {round(stop-start, 2)}\")\n",
    "\n",
    "    if plot_every is None:\n",
    "      plot_every = int(num_epochs/10)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        start = time.time()\n",
    "        epoch_train_loss, train_accuracy, train_balanced_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_balanced_accuracies.append(train_balanced_acc)\n",
    "\n",
    "        # Validation\n",
    "        epoch_val_loss, val_accuracy, val_balanced_acc = validate(model, val_loader, criterion)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_balanced_accuracies.append(val_balanced_acc)\n",
    "        stop = time.time()\n",
    "\n",
    "        if epoch % plot_every == 0 or epoch == num_epochs-1:\n",
    "          print_metrics(epoch)\n",
    "\n",
    "        # Patience mechanism\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print_metrics(epoch)\n",
    "                break\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, train_balanced_accuracies, val_balanced_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qzguYsI-E3qF",
   "metadata": {
    "id": "qzguYsI-E3qF"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uieLCXxoEu4g",
   "metadata": {
    "id": "uieLCXxoEu4g"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train.cpu()), y=y_train.cpu().numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6962c74-070a-4a0d-a58e-79a1e96ab03a",
   "metadata": {
    "id": "d6962c74-070a-4a0d-a58e-79a1e96ab03a"
   },
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "lstm1 = 2048\n",
    "lstm2 = 2048\n",
    "num_layers = 2\n",
    "hidden_n = 1024\n",
    "bidirectional = True\n",
    "num_classes = 5\n",
    "num_attention_heads = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "patience = int(num_epochs/10)+np.inf\n",
    "\n",
    "add_attention = False\n",
    "\n",
    "#model = ImageLSTM(input_size, lstm1, num_layers, hidden_n, num_classes, bidirectional=bidirectional)\n",
    "model = ImageLSTMWithAttention(input_size, lstm1, lstm2, num_layers, hidden_n, num_classes, num_attention_heads, bidirectional=True, dropout_rate=0.5, add_attention=add_attention)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TEslyqWAhZPP",
   "metadata": {
    "id": "TEslyqWAhZPP"
   },
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracies, val_accuracies, train_balanced_accuracies, val_balanced_accuracies = train_with_early_stopping(\n",
    "    model, train_loader, test_loader, criterion, optimizer, num_epochs, plot_every=2, patience=patience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61gjiQZxnXjQ",
   "metadata": {
    "id": "61gjiQZxnXjQ"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "axs[0][0].plot(train_losses, label='Train loss')\n",
    "axs[1][0].plot(val_losses, label='Test loss')\n",
    "\n",
    "axs[0][1].plot(train_balanced_accuracies, label='Train Balanced Acc')\n",
    "axs[1][1].plot(val_balanced_accuracies, label='Test Balanced Acc')\n",
    "\n",
    "axs[0][2].plot(train_accuracies, label='Train Accuracy')\n",
    "axs[1][2].plot(val_accuracies, label='Test Accuracy')\n",
    "\n",
    "for ax in axs:\n",
    "  for sub_ax in ax:\n",
    "    sub_ax.legend()\n",
    "    sub_ax.grid('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GUQEMVFCh_Rp",
   "metadata": {
    "id": "GUQEMVFCh_Rp"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            test_predictions.extend(predictions.cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_balanced_acc = balanced_accuracy_score(test_labels, test_predictions)\n",
    "    print(f\"Test Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "    return test_balanced_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pWpCy8-ciN2d",
   "metadata": {
    "id": "pWpCy8-ciN2d"
   },
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_balanced_acc = test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
