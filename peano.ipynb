{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfe83f2-41cb-49eb-b2b8-5c788db6d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d7c7cd5-1d8f-4f20-9e28-46e7fa2cb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gilbert2d import gilbert2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320f5ba-7ba8-4e94-90b9-43716de90782",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129ee3b0-7c39-4dfe-8bf3-5b8ff2219c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"asymetric\", \"banded\", \"locked\", \"butterfly\", \"no_pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdbe6ad6-800f-4bf2-9b5c-2abc3b59cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping int to categories\n",
    "int_to_cat = {\n",
    "    0: \"asymetric\",\n",
    "    1: \"banded\",\n",
    "    2: \"locked\",\n",
    "    3: \"butterfly\",\n",
    "    4: \"no_pattern\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a849af-6b7c-4ffd-83f2-3bf6c2971442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"./data/X_train.npy\")\n",
    "y_train_df = pd.read_csv(\"./data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc087a3f-2484-4078-b708-d9779bc51176",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_test_df = pd.read_csv(\"./data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cdff4c-bd71-45c2-81b9-b3a160cef502",
   "metadata": {},
   "source": [
    "## Flatten with Peano curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ceba34-f023-44d6-813c-56e84a971f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_with_peano(image):\n",
    "    # Initialize empty flattened image array\n",
    "    flattened_image = np.zeros(np.prod(image.shape))\n",
    "    peano_points = gilbert2d(image.shape[0], image.shape[1])\n",
    "\n",
    "    flattened_image_index = 0\n",
    "    for row, col in peano_points:\n",
    "        flattened_image[flattened_image_index] = image[row, col]\n",
    "        flattened_image_index += 1\n",
    "\n",
    "    return flattened_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35959286-b811-49d9-aeea-56de76fc1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_img_train = [flatten_with_peano(img) for img in X_train]\n",
    "flattened_img_test = [flatten_with_peano(img) for img in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8466d6-cc01-46ad-b116-e09196751ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(np.array(flattened_img_train), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_df['cat_num'].values, dtype=torch.long)\n",
    "\n",
    "X_test = torch.tensor(np.array(flattened_img_test), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df['cat_num'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa3293a-ed04-4416-8431-8c62aaa6098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape -> torch.Size([620, 16200]), y_train shape -> torch.Size([620])\n",
      "X_test shape -> torch.Size([68, 16200]), y_test shape -> torch.Size([68])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape -> {X_train.shape}, y_train shape -> {y_train.shape}\")\n",
    "print(f\"X_test shape -> {X_test.shape}, y_test shape -> {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52222955-42b5-495e-9063-363c3fd36908",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d05003b-e72a-4805-9bfd-9ea20cb013c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ac694a-c74d-4956-8cce-500d99d24d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageLSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_classes, bidirectional=True):\n",
    "        super(ImageLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, 50, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc1 = nn.Linear(50, 32)\n",
    "        self.fc_out = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = F.relu(self.fc1(lstm_out))\n",
    "        out = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6962c74-070a-4a0d-a58e-79a1e96ab03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on cuda.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 14.54 GiB of which 5.44 MiB is free. Process 1991428 has 1.63 GiB memory in use. Process 3167848 has 11.08 GiB memory in use. Process 1211536 has 1.71 GiB memory in use. Process 3332249 has 88.00 MiB memory in use. Of the allocated memory 25.04 MiB is allocated by PyTorch, and 4.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel running on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m ImageLSTM(input_size, num_layers, num_classes, bidirectional\u001b[38;5;241m=\u001b[39mbidirectional)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/rnn.py:213\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 213\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_flat_weights()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacty of 14.54 GiB of which 5.44 MiB is free. Process 1991428 has 1.63 GiB memory in use. Process 3167848 has 11.08 GiB memory in use. Process 1211536 has 1.71 GiB memory in use. Process 3332249 has 88.00 MiB memory in use. Of the allocated memory 25.04 MiB is allocated by PyTorch, and 4.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "num_classes = 5\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Model running on {device}.\")\n",
    "model = ImageLSTM(input_size, num_layers, num_classes, bidirectional=bidirectional)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef538349-d674-4267-962c-04fbc104e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"Validation Accuracy: {:.2%}\".format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
